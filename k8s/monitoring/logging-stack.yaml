apiVersion: v1
kind: Namespace
metadata:
  name: logging
  labels:
    name: logging
    environment: production
    
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: logging
data:
  loki.yaml: |
    auth_enabled: false
    
    server:
      http_listen_port: 3100
      grpc_listen_port: 9096
      log_level: info
    
    common:
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        kvstore:
          store: inmemory
    
    query_range:
      results_cache:
        cache:
          embedded_cache:
            enabled: true
            max_size_mb: 100
    
    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h
    
    ruler:
      alertmanager_url: http://alertmanager.monitoring:9093
      storage:
        type: local
        local:
          directory: /loki/rules
      rule_path: /loki/rules
      ring:
        kvstore:
          store: inmemory
      enable_api: true
    
    limits_config:
      enforce_metric_name: false
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      ingestion_rate_mb: 10
      ingestion_burst_size_mb: 20
      max_streams_per_user: 10000
      max_line_size: 256000
    
    chunk_store_config:
      max_look_back_period: 0s
    
    table_manager:
      retention_deletes_enabled: true
      retention_period: 168h

  loki-rules.yaml: |
    groups:
    - name: waqiti.logs.alerts
      rules:
      - alert: HighErrorRate
        expr: |
          (
            sum(rate({job=~"waqiti-.*"} |= "ERROR" [5m])) by (job)
            /
            sum(rate({job=~"waqiti-.*"}[5m])) by (job)
          ) > 0.05
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High error rate in logs"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.job }}"
          
      - alert: CriticalErrorSpike
        expr: |
          sum(rate({job=~"waqiti-.*"} |= "CRITICAL" [5m])) by (job) > 0.1
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Critical error spike detected"
          description: "Critical errors spiking for {{ $labels.job }}"
          
      - alert: PaymentErrorIncrease
        expr: |
          sum(rate({job="payment-service"} |= "ERROR" [5m])) > 0.01
        for: 2m
        labels:
          severity: critical
          service: payment
          team: payments
        annotations:
          summary: "Payment service error rate increased"
          description: "Payment service showing increased error rates"
          
      - alert: SecurityLogAlert
        expr: |
          sum(rate({job=~".*"} |~ "(?i)(unauthorized|forbidden|hack|attack|breach)" [5m])) > 0
        for: 1m
        labels:
          severity: critical
          team: security
        annotations:
          summary: "Security-related log entries detected"
          description: "Potential security incidents in logs"
          
      - alert: DatabaseConnectionErrors
        expr: |
          sum(rate({job=~".*"} |~ "(?i)(connection.*failed|database.*error|sql.*exception)" [5m])) > 0.01
        for: 2m
        labels:
          severity: warning
          service: database
          team: platform
        annotations:
          summary: "Database connection errors detected"
          description: "Increased database connection errors in application logs"

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
  namespace: logging
spec:
  serviceName: loki
  replicas: 1
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 10001
        fsGroup: 10001
      containers:
      - name: loki
        image: grafana/loki:2.8.0
        args:
          - -config.file=/etc/loki/loki.yaml
          - -target=all
        ports:
        - containerPort: 3100
          name: http
        - containerPort: 9096
          name: grpc
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
        - name: loki-config
          mountPath: /etc/loki
          readOnly: true
        - name: loki-storage
          mountPath: /loki
        - name: loki-rules
          mountPath: /loki/rules
          readOnly: true
        livenessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
          periodSeconds: 10
      volumes:
      - name: loki-config
        configMap:
          name: loki-config
          items:
          - key: loki.yaml
            path: loki.yaml
      - name: loki-rules
        configMap:
          name: loki-config
          items:
          - key: loki-rules.yaml
            path: loki-rules.yaml
  volumeClaimTemplates:
  - metadata:
      name: loki-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: gp3
      resources:
        requests:
          storage: 50Gi

---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: logging
  labels:
    app: loki
spec:
  type: ClusterIP
  ports:
  - port: 3100
    targetPort: 3100
    name: http
  - port: 9096
    targetPort: 9096
    name: grpc
  selector:
    app: loki

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: logging
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0
    
    positions:
      filename: /tmp/positions.yaml
    
    clients:
      - url: http://loki.logging:3100/loki/api/v1/push
    
    scrape_configs:
    # Kubernetes pod logs
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
        - role: pod
      pipeline_stages:
        - cri: {}
      relabel_configs:
        - source_labels:
            - __meta_kubernetes_pod_controller_name
          regex: ([0-9a-z-.]+?)(-[0-9a-f]{8,10})?
          action: replace
          target_label: __tmp_controller_name
        - source_labels:
            - __meta_kubernetes_pod_label_app_kubernetes_io_name
            - __meta_kubernetes_pod_label_app
            - __tmp_controller_name
            - __meta_kubernetes_pod_name
          regex: ^;*([^;]+)(;.*)?$
          action: replace
          target_label: app
        - source_labels:
            - __meta_kubernetes_pod_label_app_kubernetes_io_instance
            - __meta_kubernetes_pod_label_release
          regex: ^;*([^;]+)(;.*)?$
          action: replace
          target_label: instance
        - source_labels:
            - __meta_kubernetes_pod_label_app_kubernetes_io_component
            - __meta_kubernetes_pod_label_component
          regex: ^;*([^;]+)(;.*)?$
          action: replace
          target_label: component
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_node_name
          target_label: node_name
        - action: replace
          source_labels:
          - __meta_kubernetes_namespace
          target_label: namespace
        - action: replace
          replacement: $1
          separator: /
          source_labels:
          - namespace
          - app
          target_label: job
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_name
          target_label: pod
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_container_name
          target_label: container
        - action: replace
          replacement: /var/log/pods/*$1/*.log
          separator: /
          source_labels:
          - __meta_kubernetes_pod_uid
          - __meta_kubernetes_pod_container_name
          target_label: __path__
    
    # Waqiti-specific log parsing
    - job_name: waqiti-services
      kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - example-prod
      pipeline_stages:
        - cri: {}
        - regex:
            expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}) \[(?P<thread>[^\]]+)\] (?P<level>\w+)\s+\[(?P<logger>[^\]]+)\] - (?P<message>.*)$'
        - labels:
            level:
            thread:
            logger:
        - timestamp:
            source: timestamp
            format: '2006-01-02 15:04:05.000'
        - output:
            source: message
      relabel_configs:
        - source_labels: [__meta_kubernetes_pod_label_app]
          target_label: service
        - source_labels: [__meta_kubernetes_pod_label_version]
          target_label: version
        - source_labels: [__meta_kubernetes_namespace]
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          target_label: pod
        - source_labels: [__meta_kubernetes_pod_container_name]
          target_label: container
        - replacement: /var/log/pods/*$1/*.log
          separator: /
          source_labels:
          - __meta_kubernetes_pod_uid
          - __meta_kubernetes_pod_container_name
          target_label: __path__

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: logging
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
    spec:
      serviceAccountName: promtail
      securityContext:
        runAsNonRoot: true
        runAsUser: 0
      containers:
      - name: promtail
        image: grafana/promtail:2.8.0
        args:
          - -config.file=/etc/promtail/promtail.yaml
        env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        ports:
        - containerPort: 9080
          name: http
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        volumeMounts:
        - name: promtail-config
          mountPath: /etc/promtail
          readOnly: true
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: promtail-config
        configMap:
          name: promtail-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      tolerations:
      - effect: NoSchedule
        operator: Exists
      - effect: NoExecute
        operator: Exists

---
apiVersion: v1
kind: Service
metadata:
  name: promtail
  namespace: logging
  labels:
    app: promtail
spec:
  type: ClusterIP
  ports:
  - port: 9080
    targetPort: 9080
    name: http
  selector:
    app: promtail

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: logging

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: promtail
subjects:
- kind: ServiceAccount
  name: promtail
  namespace: logging

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: logging
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020
    
    [INPUT]
        Name              tail
        Path              /var/log/containers/*waqiti*.log
        Parser            cri
        Tag               kube.*
        Refresh_Interval  5
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On
    
    [FILTER]
        Name                kubernetes
        Match               kube.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Merge_Log           On
        Keep_Log            Off
        K8S-Logging.Parser  On
        K8S-Logging.Exclude On
        Annotations         Off
        Labels              On
    
    [FILTER]
        Name    grep
        Match   kube.*
        Regex   kubernetes.namespace_name ^example-prod$
    
    [OUTPUT]
        Name            loki
        Match           kube.*
        Host            loki.logging
        Port            3100
        Labels          job=fluent-bit,namespace=$kubernetes['namespace_name'],pod=$kubernetes['pod_name'],container=$kubernetes['container_name']
        Auto_Kubernetes_Labels on
    
    [OUTPUT]
        Name            es
        Match           kube.*
        Host            elasticsearch.logging
        Port            9200
        Index           waqiti-logs
        Type            _doc
        Logstash_Format On
        Logstash_Prefix waqiti
        Retry_Limit     False

  parsers.conf: |
    [PARSER]
        Name        cri
        Format      regex
        Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z
    
    [PARSER]
        Name        waqiti-java
        Format      regex
        Regex       ^(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}) \[(?<thread>[^\]]+)\] (?<level>\w+)\s+\[(?<logger>[^\]]+)\] - (?<message>.*)$
        Time_Key    timestamp
        Time_Format %Y-%m-%d %H:%M:%S.%L

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: logging
spec:
  selector:
    matchLabels:
      app: fluent-bit
  template:
    metadata:
      labels:
        app: fluent-bit
    spec:
      serviceAccountName: fluent-bit
      tolerations:
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:2.1.4
        ports:
        - containerPort: 2020
          name: http
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
        volumeMounts:
        - name: fluent-bit-config
          mountPath: /fluent-bit/etc/
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: fluent-bit-config
        configMap:
          name: fluent-bit-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluent-bit
  namespace: logging

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluent-bit
rules:
- apiGroups: [""]
  resources:
  - pods
  - namespaces
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluent-bit
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluent-bit
subjects:
- kind: ServiceAccount
  name: fluent-bit
  namespace: logging