# Predictive Auto-Scaling with ML-based Demand Forecasting
# Advanced horizontal pod autoscaler using machine learning for proactive scaling

apiVersion: v1
kind: Namespace
metadata:
  name: waqiti-scaling
  labels:
    istio-injection: enabled

---
# ConfigMap for ML Prediction Service Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: predictive-autoscaler-config
  namespace: waqiti-scaling
data:
  config.yaml: |
    # ML-based Predictive Scaling Configuration
    prediction:
      # Model configuration
      model_type: "lstm_ensemble"
      prediction_horizon_minutes: 30
      historical_window_hours: 168  # 7 days
      retraining_interval_hours: 24
      model_accuracy_threshold: 0.85
      
      # Feature engineering
      features:
        - transaction_volume
        - user_activity
        - api_request_rate
        - payment_velocity
        - seasonal_patterns
        - day_of_week
        - hour_of_day
        - holiday_indicator
        - business_events
        - external_factors
      
      # Scaling parameters
      scaling:
        # Prediction confidence thresholds
        high_confidence_threshold: 0.9
        medium_confidence_threshold: 0.7
        low_confidence_threshold: 0.5
        
        # Scaling factors
        scale_up_multiplier: 1.5
        scale_down_multiplier: 0.7
        max_scale_up_pods: 20
        max_scale_down_pods: 5
        
        # Safety margins
        prediction_buffer_percentage: 20
        minimum_replicas: 2
        maximum_replicas: 100
        
        # Cooldown periods
        scale_up_cooldown_minutes: 5
        scale_down_cooldown_minutes: 10
        
        # Performance targets
        target_cpu_utilization: 70
        target_memory_utilization: 80
        target_response_time_ms: 200
        target_error_rate: 0.01
    
    # Data sources for prediction
    data_sources:
      prometheus:
        url: "http://prometheus.example-monitoring:9090"
        metrics:
          - container_cpu_usage_seconds_total
          - container_memory_working_set_bytes
          - http_requests_total
          - http_request_duration_seconds
          - payment_transactions_total
          - user_sessions_active
          - fraud_detection_requests_total
          
      kafka:
        bootstrap_servers: "waqiti-kafka:9092"
        topics:
          - transaction-events
          - user-activity
          - payment-events
          - fraud-detection-results
          
      database:
        connection_string: "${DATABASE_URL}"
        queries:
          hourly_transaction_volume: |
            SELECT DATE_TRUNC('hour', created_at) as hour,
                   COUNT(*) as transaction_count,
                   SUM(amount) as total_amount
            FROM transactions 
            WHERE created_at >= NOW() - INTERVAL '7 days'
            GROUP BY hour
            ORDER BY hour
          
          user_activity_patterns: |
            SELECT DATE_TRUNC('hour', last_activity) as hour,
                   COUNT(DISTINCT user_id) as active_users
            FROM user_sessions
            WHERE last_activity >= NOW() - INTERVAL '7 days'
            GROUP BY hour
            ORDER BY hour
    
    # External data integration
    external_data:
      # Business events calendar
      business_events:
        enabled: true
        calendar_url: "https://api.example.com/events/calendar"
        types:
          - marketing_campaigns
          - product_launches
          - seasonal_promotions
          - maintenance_windows
          
      # Economic indicators
      economic_data:
        enabled: true
        sources:
          - stock_market_indices
          - currency_exchange_rates
          - economic_announcements
          
      # Weather data (for seasonal patterns)
      weather_data:
        enabled: true
        api_key: "${WEATHER_API_KEY}"
        locations:
          - "US"
          - "CA"
          - "GB"
          - "DE"
    
    # Model training configuration
    training:
      # AutoML configuration
      automl:
        enabled: true
        algorithm_selection:
          - lstm
          - prophet
          - arima
          - xgboost
          - random_forest
        hyperparameter_tuning:
          enabled: true
          max_trials: 50
          optimization_metric: "mean_absolute_percentage_error"
          
      # Training data preparation
      data_preparation:
        outlier_detection: true
        missing_value_strategy: "interpolation"
        normalization: "z_score"
        feature_selection: "recursive_feature_elimination"
        
      # Model validation
      validation:
        method: "time_series_split"
        test_size_percentage: 20
        cross_validation_folds: 5
        walk_forward_validation: true
        
    # Alerting and monitoring
    monitoring:
      alerts:
        prediction_accuracy_drop:
          threshold: 0.8
          severity: "warning"
        model_training_failure:
          severity: "critical"
        scaling_event_frequency:
          threshold: 10  # per hour
          severity: "warning"
        resource_prediction_deviation:
          threshold: 30  # percentage
          severity: "warning"
          
      metrics:
        - prediction_accuracy
        - scaling_events_total
        - prediction_latency
        - model_training_duration
        - cost_optimization_percentage

---
# Deployment for ML Prediction Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-prediction-service
  namespace: waqiti-scaling
  labels:
    app: ml-prediction-service
    component: autoscaler
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ml-prediction-service
  template:
    metadata:
      labels:
        app: ml-prediction-service
        component: autoscaler
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: predictive-autoscaler
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
      containers:
      - name: ml-predictor
        image: waqiti/ml-prediction-service:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 8090
          name: grpc
        env:
        - name: CONFIG_PATH
          value: "/etc/config/config.yaml"
        - name: PROMETHEUS_URL
          value: "http://prometheus.example-monitoring:9090"
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "waqiti-kafka:9092"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-credentials
              key: connection_string
        - name: WEATHER_API_KEY
          valueFrom:
            secretKeyRef:
              name: external-api-keys
              key: weather_api_key
        - name: LOG_LEVEL
          value: "INFO"
        volumeMounts:
        - name: config
          mountPath: /etc/config
          readOnly: true
        - name: model-storage
          mountPath: /var/lib/models
        - name: tmp
          mountPath: /tmp
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
      volumes:
      - name: config
        configMap:
          name: predictive-autoscaler-config
      - name: model-storage
        persistentVolumeClaim:
          claimName: ml-models-pvc
      - name: tmp
        emptyDir: {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: ml-prediction-service
              topologyKey: kubernetes.io/hostname

---
# Service for ML Prediction Service
apiVersion: v1
kind: Service
metadata:
  name: ml-prediction-service
  namespace: waqiti-scaling
  labels:
    app: ml-prediction-service
spec:
  type: ClusterIP
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
    name: http
  - port: 8090
    targetPort: 8090
    protocol: TCP
    name: grpc
  selector:
    app: ml-prediction-service

---
# PersistentVolumeClaim for ML Models Storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ml-models-pvc
  namespace: waqiti-scaling
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: fast-ssd

---
# ServiceAccount for Predictive Autoscaler
apiVersion: v1
kind: ServiceAccount
metadata:
  name: predictive-autoscaler
  namespace: waqiti-scaling

---
# ClusterRole for accessing metrics and scaling resources
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: predictive-autoscaler
rules:
# HPA management
- apiGroups: ["autoscaling"]
  resources: ["horizontalpodautoscalers"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
# Deployment and ReplicaSet access
- apiGroups: ["apps"]
  resources: ["deployments", "deployments/scale", "replicasets"]
  verbs: ["get", "list", "watch", "update", "patch"]
# Pod metrics access
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
# Metrics access
- apiGroups: ["metrics.k8s.io"]
  resources: ["pods", "nodes"]
  verbs: ["get", "list"]
# Custom metrics access
- apiGroups: ["custom.metrics.k8s.io"]
  resources: ["*"]
  verbs: ["get", "list"]
# Events for logging scaling decisions
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create", "patch"]
# ConfigMaps for configuration
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "list", "watch"]

---
# ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: predictive-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: predictive-autoscaler
subjects:
- kind: ServiceAccount
  name: predictive-autoscaler
  namespace: waqiti-scaling

---
# Custom Resource Definition for Predictive HPA
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: predictivehpas.autoscaling.example.com
spec:
  group: autoscaling.example.com
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              scaleTargetRef:
                type: object
                properties:
                  apiVersion:
                    type: string
                  kind:
                    type: string
                  name:
                    type: string
              minReplicas:
                type: integer
                minimum: 1
              maxReplicas:
                type: integer
                minimum: 1
              predictionHorizonMinutes:
                type: integer
                minimum: 5
                maximum: 120
                default: 30
              targetMetrics:
                type: array
                items:
                  type: object
                  properties:
                    type:
                      type: string
                      enum: ["Resource", "Pods", "Object", "External"]
                    resource:
                      type: object
                      properties:
                        name:
                          type: string
                        target:
                          type: object
                    external:
                      type: object
                      properties:
                        metric:
                          type: object
                        target:
                          type: object
              mlModelConfig:
                type: object
                properties:
                  modelType:
                    type: string
                    enum: ["lstm", "prophet", "arima", "ensemble"]
                    default: "ensemble"
                  retrainingIntervalHours:
                    type: integer
                    minimum: 1
                    maximum: 168
                    default: 24
                  accuracyThreshold:
                    type: number
                    minimum: 0.0
                    maximum: 1.0
                    default: 0.85
          status:
            type: object
            properties:
              currentReplicas:
                type: integer
              desiredReplicas:
                type: integer
              lastPrediction:
                type: string
                format: date-time
              predictionAccuracy:
                type: number
              modelVersion:
                type: string
              conditions:
                type: array
                items:
                  type: object
                  properties:
                    type:
                      type: string
                    status:
                      type: string
                    lastTransitionTime:
                      type: string
                      format: date-time
                    reason:
                      type: string
                    message:
                      type: string
  scope: Namespaced
  names:
    plural: predictivehpas
    singular: predictivehpa
    kind: PredictiveHPA
    shortNames:
    - phpa

---
# Example Predictive HPA for Payment Service
apiVersion: autoscaling.example.com/v1
kind: PredictiveHPA
metadata:
  name: payment-service-predictive-hpa
  namespace: waqiti
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: payment-service
  minReplicas: 3
  maxReplicas: 50
  predictionHorizonMinutes: 30
  targetMetrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: External
    external:
      metric:
        name: payment_requests_per_second
        selector:
          matchLabels:
            service: payment-service
      target:
        type: Value
        value: "100"
  - type: External
    external:
      metric:
        name: fraud_detection_queue_length
        selector:
          matchLabels:
            service: ml-service
      target:
        type: Value
        value: "50"
  mlModelConfig:
    modelType: "ensemble"
    retrainingIntervalHours: 12
    accuracyThreshold: 0.9

---
# Predictive HPA for Transaction Service
apiVersion: autoscaling.example.com/v1
kind: PredictiveHPA
metadata:
  name: transaction-service-predictive-hpa
  namespace: waqiti
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: transaction-service
  minReplicas: 2
  maxReplicas: 30
  predictionHorizonMinutes: 30
  targetMetrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: External
    external:
      metric:
        name: transaction_processing_rate
        selector:
          matchLabels:
            service: transaction-service
      target:
        type: Value
        value: "200"
  mlModelConfig:
    modelType: "lstm"
    retrainingIntervalHours: 24
    accuracyThreshold: 0.85

---
# Predictive HPA for ML Service
apiVersion: autoscaling.example.com/v1
kind: PredictiveHPA
metadata:
  name: ml-service-predictive-hpa
  namespace: waqiti
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ml-service
  minReplicas: 2
  maxReplicas: 20
  predictionHorizonMinutes: 15  # Shorter horizon for real-time ML
  targetMetrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 80
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 85
  - type: External
    external:
      metric:
        name: fraud_detection_requests_per_second
        selector:
          matchLabels:
            service: ml-service
      target:
        type: Value
        value: "50"
  mlModelConfig:
    modelType: "prophet"  # Good for time series with seasonal patterns
    retrainingIntervalHours: 6
    accuracyThreshold: 0.9

---
# ServiceMonitor for Predictive Autoscaler Metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: predictive-autoscaler
  namespace: waqiti-scaling
  labels:
    app: ml-prediction-service
spec:
  selector:
    matchLabels:
      app: ml-prediction-service
  endpoints:
  - port: http
    interval: 30s
    path: /metrics

---
# NetworkPolicy for ML Prediction Service
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ml-prediction-service-netpol
  namespace: waqiti-scaling
spec:
  podSelector:
    matchLabels:
      app: ml-prediction-service
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Allow Kubernetes API access
  - from: []
    ports:
    - protocol: TCP
      port: 8080
    - protocol: TCP
      port: 8090
  egress:
  # Allow DNS
  - to: []
    ports:
    - protocol: UDP
      port: 53
  # Allow Kubernetes API
  - to: []
    ports:
    - protocol: TCP
      port: 443
  # Allow Prometheus access
  - to:
    - namespaceSelector:
        matchLabels:
          name: example-monitoring
    ports:
    - protocol: TCP
      port: 9090
  # Allow Kafka access
  - to:
    - namespaceSelector:
        matchLabels:
          name: waqiti
    ports:
    - protocol: TCP
      port: 9092
  # Allow database access
  - to: []
    ports:
    - protocol: TCP
      port: 5432

---
# Pod Disruption Budget
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: ml-prediction-service-pdb
  namespace: waqiti-scaling
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: ml-prediction-service